{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datetime_features(df):\n",
    "    df['hour'] = df['local_15min'].dt.hour\n",
    "    df['minute'] = df['local_15min'].dt.minute\n",
    "    df['day_of_week'] = df['local_15min'].dt.dayofweek\n",
    "    df['day_of_month'] = df['local_15min'].dt.day\n",
    "    df['month'] = df['local_15min'].dt.month\n",
    "    df['weekend'] = df['local_15min'].dt.dayofweek >= 5  # True if it's a weekend (Saturday or Sunday)\n",
    "    df['ev_present'] = df['ev_car'].apply(lambda x: 1 if x >=1 else 0)  # True if there is an electric vehicle present\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Ensure the datetime column is in the correct format\n",
    "    df['local_15min'] = pd.to_datetime(df['local_15min'], utc=True)\n",
    "\n",
    "    # Extract useful features from datetime\n",
    "    df = extract_datetime_features(df)\n",
    "\n",
    "    # Drop the original datetime column (or keep it if necessary)\n",
    "    df = df.drop(columns=['local_15min', 'ev_car', 'solar', 'grid', 'total_usage'])\n",
    "\n",
    "    # Encode categorical columns (if 'house_type', 'day_of_the_week', etc. are categorical)\n",
    "    label_encoders = {}\n",
    "    for column in ['house_type']:  # Add other categorical columns as needed\n",
    "        label_encoders[column] = LabelEncoder()\n",
    "        df[column] = label_encoders[column].fit_transform(df[column])\n",
    "\n",
    "    # Extract features and label\n",
    "    y = df['ev_present'].values\n",
    "    df.drop(columns=['ev_present'], inplace=True)\n",
    "    X = df.values  # Features (everything except 'ev_present')\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=False)\n",
    "\n",
    "    # Standardize the features (important for some models)\n",
    "    # scaler = StandardScaler()\n",
    "    # X_train = scaler.fit_transform(X_train)\n",
    "    # X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_with_grid_search(X_train, y_train, X_test, y_test):\n",
    "    # Initialize the Random Forest model\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    # Define hyperparameters to tune\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    \n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    \n",
    "    # Fit GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model from Grid Search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Make predictions on the train and test sets\n",
    "    y_pred_train = best_model.predict(X_train)\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Precision, recall, and F1-score\n",
    "    precision = precision_score(y_test, y_pred_test, average='binary', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred_test, average='binary', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_test, average='binary', zero_division=0)\n",
    "    \n",
    "    # Cross-validation scores\n",
    "    cv_scores = grid_search.best_score_\n",
    "    print(f\"Cross-validation scores: {cv_scores}\")\n",
    "\n",
    "    print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\nDetailed Classification Report:\\n\", classification_report(y_test, y_pred_test))\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df):\n",
    "    # Preprocess the data\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(df)\n",
    "\n",
    "    # Train and evaluate the Decision Tree model\n",
    "    train_random_forest_with_grid_search(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'pecan_street'\n",
    "area = 'austin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "House 661:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Cross-validation scores: 0.981502569561427\n",
      "Training Accuracy: 0.9933\n",
      "Test Accuracy: 0.9717\n",
      "Precision: 0.9875\n",
      "Recall: 0.5651\n",
      "F1 Score: 0.7188\n",
      "\n",
      "Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      8197\n",
      "           1       0.99      0.57      0.72       561\n",
      "\n",
      "    accuracy                           0.97      8758\n",
      "   macro avg       0.98      0.78      0.85      8758\n",
      "weighted avg       0.97      0.97      0.97      8758\n",
      "\n",
      "Best parameters found:  {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "House 1642:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Cross-validation scores: 0.966712104824438\n",
      "Training Accuracy: 0.9872\n",
      "Test Accuracy: 0.9427\n",
      "Precision: 0.9817\n",
      "Recall: 0.4340\n",
      "F1 Score: 0.6019\n",
      "\n",
      "Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7798\n",
      "           1       0.98      0.43      0.60       864\n",
      "\n",
      "    accuracy                           0.94      8662\n",
      "   macro avg       0.96      0.72      0.79      8662\n",
      "weighted avg       0.95      0.94      0.93      8662\n",
      "\n",
      "Best parameters found:  {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "House 4373:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Cross-validation scores: 0.9550177692656936\n",
      "Training Accuracy: 0.9727\n",
      "Test Accuracy: 0.8937\n",
      "Precision: 0.9557\n",
      "Recall: 0.2767\n",
      "F1 Score: 0.4291\n",
      "\n",
      "Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7386\n",
      "           1       0.96      0.28      0.43      1247\n",
      "\n",
      "    accuracy                           0.89      8633\n",
      "   macro avg       0.92      0.64      0.69      8633\n",
      "weighted avg       0.90      0.89      0.87      8633\n",
      "\n",
      "Best parameters found:  {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "House 4767:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Cross-validation scores: 0.9764680974509181\n",
      "Training Accuracy: 0.9872\n",
      "Test Accuracy: 0.9930\n",
      "Precision: 0.9903\n",
      "Recall: 0.8779\n",
      "F1 Score: 0.9308\n",
      "\n",
      "Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      8273\n",
      "           1       0.99      0.88      0.93       467\n",
      "\n",
      "    accuracy                           0.99      8740\n",
      "   macro avg       0.99      0.94      0.96      8740\n",
      "weighted avg       0.99      0.99      0.99      8740\n",
      "\n",
      "Best parameters found:  {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "House 6139:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Cross-validation scores: 0.9642647141882703\n",
      "Training Accuracy: 0.9803\n",
      "Test Accuracy: 0.9726\n",
      "Precision: 0.2188\n",
      "Recall: 0.1129\n",
      "F1 Score: 0.1489\n",
      "\n",
      "Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      8573\n",
      "           1       0.22      0.11      0.15       186\n",
      "\n",
      "    accuracy                           0.97      8759\n",
      "   macro avg       0.60      0.55      0.57      8759\n",
      "weighted avg       0.96      0.97      0.97      8759\n",
      "\n",
      "Best parameters found:  {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "House 8156:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Cross-validation scores: 0.953884769229339\n",
      "Training Accuracy: 0.9591\n",
      "Test Accuracy: 0.9421\n",
      "Precision: 0.7500\n",
      "Recall: 0.2003\n",
      "F1 Score: 0.3162\n",
      "\n",
      "Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      8162\n",
      "           1       0.75      0.20      0.32       584\n",
      "\n",
      "    accuracy                           0.94      8746\n",
      "   macro avg       0.85      0.60      0.64      8746\n",
      "weighted avg       0.93      0.94      0.93      8746\n",
      "\n",
      "Best parameters found:  {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "houses = [661, 1642, 4373, 4767, 6139, 8156]\n",
    "for house in houses:\n",
    "    df = pd.read_csv(f'../../Dataset/{source}/{area}/house_energy_compressed/{house}_compressed.csv', parse_dates=['local_15min'])\n",
    "    print(f\"\\nHouse {house}:\")\n",
    "    main(df)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "House 27:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Cross-validation scores: 0.9913944315049468\n",
      "Training Accuracy: 0.9925\n",
      "Test Accuracy: 0.9925\n",
      "Precision: 0.9653\n",
      "Recall: 0.9476\n",
      "F1 Score: 0.9564\n",
      "\n",
      "Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4034\n",
      "           1       0.97      0.95      0.96       382\n",
      "\n",
      "    accuracy                           0.99      4416\n",
      "   macro avg       0.98      0.97      0.98      4416\n",
      "weighted avg       0.99      0.99      0.99      4416\n",
      "\n",
      "Best parameters found:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "House 3000:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Cross-validation scores: 0.9818072750842255\n",
      "Training Accuracy: 0.9952\n",
      "Test Accuracy: 0.9880\n",
      "Precision: 0.9446\n",
      "Recall: 0.9236\n",
      "F1 Score: 0.9340\n",
      "\n",
      "Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4010\n",
      "           1       0.94      0.92      0.93       406\n",
      "\n",
      "    accuracy                           0.99      4416\n",
      "   macro avg       0.97      0.96      0.96      4416\n",
      "weighted avg       0.99      0.99      0.99      4416\n",
      "\n",
      "Best parameters found:  {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "House 5679:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Cross-validation scores: 0.9923763613182619\n",
      "Training Accuracy: 0.9963\n",
      "Test Accuracy: 0.9887\n",
      "Precision: 0.9777\n",
      "Recall: 0.7919\n",
      "F1 Score: 0.8750\n",
      "\n",
      "Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4195\n",
      "           1       0.98      0.79      0.88       221\n",
      "\n",
      "    accuracy                           0.99      4416\n",
      "   macro avg       0.98      0.90      0.93      4416\n",
      "weighted avg       0.99      0.99      0.99      4416\n",
      "\n",
      "Best parameters found:  {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "House 9053:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Cross-validation scores: 0.9318378028020542\n",
      "Training Accuracy: 0.9593\n",
      "Test Accuracy: 0.9425\n",
      "Precision: 0.5860\n",
      "Recall: 0.6422\n",
      "F1 Score: 0.6128\n",
      "\n",
      "Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      4103\n",
      "           1       0.59      0.64      0.61       313\n",
      "\n",
      "    accuracy                           0.94      4416\n",
      "   macro avg       0.78      0.80      0.79      4416\n",
      "weighted avg       0.95      0.94      0.94      4416\n",
      "\n",
      "Best parameters found:  {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "houses = [27, 3000, 5679, 9053]\n",
    "area = 'new_york'\n",
    "for house in houses:\n",
    "    df = pd.read_csv(f'../../Dataset/{source}/{area}/house_energy_compressed/{house}_compressed.csv', parse_dates=['local_15min'])\n",
    "    print(f\"\\nHouse {house}:\")\n",
    "    main(df)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
